{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d378072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/mac/Library/Python/3.9/lib/python/site-packages (0.3.27)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75 kB 6.6 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.79)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (0.4.37)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain) (2.12.4)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0\n",
      "  Downloading tiktoken-0.12.0-cp39-cp39-macosx_11_0_arm64.whl (997 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 997 kB 22.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: openai<3.0.0,>=1.104.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-openai) (2.7.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: anyio in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.10.5)\n",
      "Requirement already satisfied: idna in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: sniffio in /Users/mac/Library/Python/3.9/lib/python/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Collecting regex>=2022.1.18\n",
      "  Downloading regex-2025.11.3-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 288 kB 63.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.3.35 regex-2025.11.3 tiktoken-0.12.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytz in /Users/mac/Library/Python/3.9/lib/python/site-packages (2025.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain langchain-openai\n",
    "!pip3 install pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af291c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "print(importlib.util.find_spec(\"langchain.chat_models\") is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8361623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "LangChain available: True\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "from typing import List, Dict, Any, Optional\n",
    "from getpass import getpass\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# src í´ë” ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ì¶”ê°€\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))\n",
    "\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain.prompts import ChatPromptTemplate\n",
    "    from langchain.chains import LLMChain\n",
    "    LANGCHAIN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGCHAIN_AVAILABLE = False\n",
    "\n",
    "from src.config import get_config\n",
    "from src.utils.logging_config import get_logger\n",
    "\n",
    "print(\"----------\")\n",
    "print(f\"LangChain available: {LANGCHAIN_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "824fb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Optional[str] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "        config=None,\n",
    "        api_key: Optional[str] = None\n",
    "    ):\n",
    "        # Config & Logger\n",
    "        self.config = config or get_config()\n",
    "        self.logger = get_logger(__name__)\n",
    "\n",
    "        self.model_name = model or self.config.OPENAI_MODEL\n",
    "        self.temperature = temperature if temperature is not None else self.config.OPENAI_TEMPERATURE\n",
    "\n",
    "        # API í‚¤ ì…ë ¥ ì²˜ë¦¬\n",
    "        if api_key is None or not api_key.strip():\n",
    "            api_key_input = getpass(\"ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "            api_key = api_key_input if api_key_input else None\n",
    "\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API Keyê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # í™˜ê²½ ë³€ìˆ˜ì— ë“±ë¡ (LangChainì—ì„œ ìë™ ì‚¬ìš©)\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "        # LangChain ì´ˆê¸°í™”\n",
    "        if LANGCHAIN_AVAILABLE:\n",
    "            self.llm = ChatOpenAI(model=self.model_name, temperature=self.temperature)\n",
    "            self.logger.info(f\"LLMProcessor ì´ˆê¸°í™” ì™„ë£Œ (model={self.model_name}, temperature={self.temperature})\")\n",
    "        else:\n",
    "            self.logger.error(\"LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            raise ImportError(\"LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    def generate_response(self, query: str, retrieved_chunks: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"ê²€ìƒ‰ëœ ì²­í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        self.logger.info(f\"LLM ì‘ë‹µ ìƒì„± ì‹œì‘: query='{query[:50]}...'\")\n",
    "\n",
    "        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "        if not retrieved_chunks:\n",
    "            context = self.config.NO_CONTEXT_MESSAGE\n",
    "            self.logger.warning(\"ê²€ìƒ‰ëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            context_parts = [\n",
    "                self.config.CONTEXT_FORMAT.format(\n",
    "                    index=i+1,\n",
    "                    file_name=chunk.get(\"file_name\", \"unknown\"),\n",
    "                    chunk_text=chunk.get(\"chunk_text\", \"\")\n",
    "                )\n",
    "                for i, chunk in enumerate(retrieved_chunks)\n",
    "            ]\n",
    "            context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        prompt = ChatPromptTemplate.from_template(self.config.RAG_PROMPT_TEMPLATE)\n",
    "        chain = prompt | self.llm\n",
    "\n",
    "        try:\n",
    "            response = chain.invoke({\"context\": context, \"query\": query})\n",
    "            self.logger.info(f\"LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(response.content)} ë¬¸ì\")\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9793ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-11 17:40:36 [I] __main__ - LLMProcessor ì´ˆê¸°í™” ì™„ë£Œ (model=gpt-4o-mini, temperature=0.0)\n",
      "2025-11-11 17:40:36 [I] __main__ - LLM ì‘ë‹µ ìƒì„± ì‹œì‘: query='íšŒì‚¬ ì •ì±…ê³¼ í”„ë¡œì íŠ¸ ì¼ì •ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ì¤˜....'\n",
      "2025-11-11 17:40:38 [I] __main__ - LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ: 117 ë¬¸ì\n",
      "\n",
      "=== LLM ì‘ë‹µ ì‹œì‘ ===\n",
      "\n",
      "íšŒì‚¬ì˜ ë‚´ë¶€ ì •ì±…ì€ ìœ ì—°ê·¼ë¬´ì œì™€ ì—°ì°¨ ê·œì • ë“±ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì¼ì •ì€ ê¸°íš ë‹¨ê³„ê°€ 2ì£¼, ê°œë°œ ë‹¨ê³„ê°€ 8ì£¼, í…ŒìŠ¤íŠ¸ ë‹¨ê³„ê°€ 2ì£¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ì€ ìš”êµ¬ì‚¬í•­ í™•ì •ê³¼ ì²« ë°°í¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "=== LLM ì‘ë‹µ ë ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_llm_demo() -> None:\n",
    "    \"\"\"\n",
    "    OpenAI ChatOpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ LLMProcessor ë™ì‘ì„ í™•ì¸í•˜ëŠ” ìµœì†Œ ì‹¤í–‰ ì˜ˆì œ\n",
    "    \"\"\"\n",
    "    # ë”ë¯¸ ê²€ìƒ‰ ì²­í¬\n",
    "    retrieved_chunks = [\n",
    "        {\n",
    "            \"file_name\": \"policy_overview.txt\",\n",
    "            \"chunk_text\": \"ì´ ë¬¸ì„œëŠ” íšŒì‚¬ì˜ ë‚´ë¶€ ì •ì±…(ì¶œí‡´ê·¼, íœ´ê°€ ë“±)ì— ëŒ€í•´ ìš”ì•½í•©ë‹ˆë‹¤. ì£¼ìš” í•­ëª©ì€ ìœ ì—°ê·¼ë¬´ì œ, ì—°ì°¨ ê·œì • ë“±ì…ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"file_name\": \"project_plan.md\",\n",
    "            \"chunk_text\": \"í”„ë¡œì íŠ¸ ì¼ì •: ê¸°íš(2ì£¼), ê°œë°œ(8ì£¼), í…ŒìŠ¤íŠ¸(2ì£¼). ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ì€ ìš”êµ¬ì‚¬í•­ í™•ì •ê³¼ ì²« ë°°í¬ì…ë‹ˆë‹¤.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    query = \"íšŒì‚¬ ì •ì±…ê³¼ í”„ë¡œì íŠ¸ ì¼ì •ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ì¤˜.\"\n",
    "\n",
    "    try:\n",
    "        processor = LLMProcessor()  # âœ… ì‹¤í–‰ ì‹œ API Key ì…ë ¥ í”„ë¡¬í”„íŠ¸\n",
    "        response = processor.generate_response(query=query, retrieved_chunks=retrieved_chunks)\n",
    "        print(\"\\n=== LLM ì‘ë‹µ ì‹œì‘ ===\\n\")\n",
    "        print(response)\n",
    "        print(\"\\n=== LLM ì‘ë‹µ ë ===\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "\n",
    "# ë°ëª¨ ì‹¤í–‰\n",
    "run_llm_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ef8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
