## 6\. 결론 및 향후 계획

### 6.1. 프로젝트 성과

본 프로젝트는 RAG(Retrieval-Augmented Generation) 기반 정부나라장터 입찰공고 분석 시스템을 개발하는 과정이었습니다. 4인의 팀원이 협력하여 프로덕션 수준의 시스템을 성공적으로 구축하였습니다.

#### 6.1.1. 기술적 성과

시스템 아키텍처는 **계층화된 설계**를 성공적으로 구현하여 모듈의 독립성과 유지보수성을 확보하였습니다.

  * **데이터 저장 계층**: 문서 원본, 벡터, 대화 이력을 위한 3개의 SQLite 데이터베이스로 구성되었습니다.
  * **데이터 접근 계층**: 각 DB에 대응하는 관리 클래스를 통해 SQL 쿼리를 추상화하였습니다.
  * **비즈니스 로직 계층**: 문서 처리, 임베딩 생성, 검색, LLM 응답 생성 등 핵심 기능을 모듈화하였습니다.
  * **사용자 인터페이스 계층**: Streamlit 기반의 직관적인 웹 애플리케이션을 제공합니다.

**문서 처리 파이프라인**은 완전 자동화되었으며 다음과 같은 성과를 거두었습니다.

  * **중복 제거**: SHA-256 해시 기반으로 2건의 중복 문서를 성공적으로 감지 및 제거하여 저장 공간과 임베딩 비용을 절감하였습니다.
  * **전처리 효율성**: PyMuPDF4LLM을 사용한 Markdown 변환 및 3단계 전처리 과정을 통해 원본 대비 평균 **21.5%의 토큰 절약**을 달성하였습니다.

**임베딩 및 벡터 저장소**는 확장 가능한 구조를 갖추었습니다.

  * **임베딩 모델**: OpenAI $text$-$embedding$-$3$-$small$ 모델을 사용하여 1536차원 벡터를 생성합니다.
  * **벡터 저장소**: FAISS $IndexFlatL2$ 인덱스를 사용하여 정확한 최근접 이웃 검색을 보장합니다.
  * **청킹 전략**: $RecursiveCharacterTextSplitter$를 사용하여 청크 크기 1500 토큰, 오버랩 300 토큰으로 컨텍스트를 보존합니다.
  * **메타데이터**: 파일 해시, 페이지 번호, 청크 인덱스 등 포괄적인 메타데이터를 첨부하여 **출처 추적 및 재현성**을 보장합니다.

**다단계 검색 시스템**은 정밀도(Precision)와 재현율(Recall)의 균형을 달성하였습니다.

  * **1차 광범위 검색**: 전체 DB 대상 유사도 검색
  * **2차 심층 검색**: $file\_hash$ 필터링을 적용하여 특정 문서의 상세 내용을 탐색

**LLM 통합**은 최신 모델을 활용하여 고품질 응답을 제공합니다.

  * **기본 모델**: $gpt$-$5$-$mini$를 채택하여 빠른 응답 속도와 낮은 비용을 실현하였습니다.
  * **컨텍스트 유지**: $ConversationSummaryMemory$를 구현하여 긴 대화에서도 토큰 한도를 준수하며 컨텍스트를 유지합니다.

**평가 시스템**은 객관적인 품질 측정을 가능하게 합니다.

  * **평가 지표**: LLM Judge 기반으로 $Faithfulness$ (신뢰도), $Context$ $Relevance$ (컨텍스트 관련성), $Answer$ $Accuracy$ (답변 정확도), $Answer$ $Relevance$ (답변 관련성)의 4대 지표로 성능을 평가합니다.

**사용자 인터페이스**는 직관성과 기능성을 갖추었습니다.

  * **UI/UX**: Streamlit 기반의 채팅 인터페이스, 세션 관리, 스트리밍 응답, 검색 결과 시각화 기능을 제공합니다.

-----

#### 6.1.2. 정량적 지표

시스템의 정량적 성능 지표는 다음과 같습니다.

| 구분 | 지표 내용 | 정량적 성과 | 출처 |
|:---|:---|:---|:---|
| **전처리 효율성** | 원본 대비 평균 토큰 절약률 | **21.5%** | |
| **비용 절감 효과** | 문서당 임베딩 비용 절감 (USD) | $0.000193$ | |
| **중복 제거 성과** | 감지 및 제거된 중복 문서 수 | 2건 | |
| **응답 생성 시간** | $gpt$-$5$-$mini$ 평균 응답 시간 | 2초 $\sim$ 5초 | |
| **DB 응답 시간** | ChatHistoryDB 메시지 조회 시간 | 10ms 이내 | |
| **FAISS 검색 시간** | 수천 벡터 대상 최근접 이웃 검색 | 10ms $\sim$ 50ms | |

-----

### 6.2. 핵심 인사이트

#### 6.2.1. RAG 시스템 설계 원칙

RAG 시스템의 성공은 각 단계의 품질 누적에 달려 있습니다.

  * **균형 잡힌 전처리**: 노이즈를 제거하면서도 의미를 보존하는 균형이 중요하며, 과도한 전처리는 정보 손실을 초래할 수 있습니다.
  * **효과적인 청킹**: 일률적인 분할보다는 페이지 경계나 의미 단위를 존중하는 접근이 효과적입니다.
  * **다단계 검색**: 1차 검색으로 후보를 좁히고 2차 검색으로 정밀도를 높이는 다단계 접근이 우수한 결과를 제공합니다.
  * **메타데이터의 중요성**: 파일 해시, 청크 해시, 설정 해시는 **재현성**과 **자동 재처리**를 가능하게 합니다.
  * **한국어 처리 고려**: 토크나이저가 한국어 텍스트를 과도하게 분할하는 경향을 고려하여 영어 대비 $20\% \sim 30\%$ 더 큰 청크 크기를 사용하는 것이 적절합니다.

#### 6.2.2. 팀 협업 및 프로젝트 관리

  * **인터페이스 우선 설계**: 프로젝트 초기에 각 모듈의 인터페이스를 문서화하고 합의하여 병렬 개발과 원활한 통합을 가능하게 하였습니다.
  * **점진적 통합**: 모든 모듈 완성 후 통합하는 빅뱅 방식 대신, 주차별로 완성된 모듈을 통합하고 엔드투엔드 테스트를 수행하여 위험을 분산시켰습니다.

#### 6.2.3. 기술 선택의 트레이드오프

  * **OpenAI 모델 의존성**: 강력한 성능을 제공하지만, API 장애 및 비용 증가 위험을 완화하기 위해 $LangChain$ 추상화를 활용하여 향후 오픈소스 모델 전환 가능성을 열어두었습니다.
  * **SQLite의 한계**: 초기 개발과 배포에는 적합하지만, 대규모 데이터 처리 및 동시 쓰기 제한으로 인해 프로덕션 환경으로 확장 시 $PostgreSQL$ 등으로 마이그레이션을 고려해야 합니다.
  * **FAISS IndexFlatL2**: 정확성을 보장하지만, 벡터 수 증가 시 검색 시간이 선형적으로 증가하여 대규모 데이터($\sim 10$만 개 이상)에서는 $IndexIVFFlat$이나 $IndexHNSW$와 같은 **근사 검색(Approximate Nearest Neighbor)** 알고리즘으로 전환이 필요합니다.

-----

### 6.3. 한계점 및 개선 과제

#### 6.3.1. 현재 시스템의 제약

  * **검색 품질**: 단순 유사도 기반 검색은 질의 의도와 맞지 않는 결과를 반환할 수 있어, 의도 분류나 엔티티 인식을 추가하여 질의 이해도를 높여야 합니다.
  * **한국어 처리 품질**: 영어 중심 모델의 한계로 인해 전문 용어 처리가 미흡하여, 한국어 특화 모델 파인튜닝이 필요합니다.
  * **확장성**: 현재 시스템은 소규모 데이터에 최적화되어 있으며, 실제 나라장터 규모의 데이터($\sim$ 수만 건)를 처리하려면 $PostgreSQL$ 및 $IndexHNSW$ 등으로의 업그레이드가 필수적입니다.
  * **보안 및 권한 관리**: 현재 단일 사용자 환경을 가정하고 있으며, 실제 배포를 위해서는 인증, 역할 기반 접근 제어($RBAC$), API 키 보호 등의 보안 기능 구현이 필요합니다.

#### 6.3.2. 사용자 피드백 부재

  * **실사용자 테스트 부족**: 프로젝트 기간 동안 팀 내부 테스트에만 의존하였으므로, 향후 파일럿 사용자 그룹을 모집하여 정성적 및 정량적 피드백을 수집해야 합니다.
  * **도메인 전문가 검증 필요**: 입찰 공고 분석의 전문성 확보를 위해 조달 전문가나 법률 자문을 통한 시스템 출력의 검토 및 개선이 필요합니다.

-----

### 6.4. 향후 개발 계획

#### 6.4.1. 단기 계획 (1개월 이내)

  * **사용자 테스트**: 파일럿 사용자를 통한 사용성, 정확성, 유용성 평가 및 피드백 수집.
  * **검색 품질 개선**: **하이브리드 검색**($BM25$ + 벡터 검색) 및 **재순위화**($Re$-$ranking$) 모델을 도입하여 검색 정밀도 향상.
  * **프롬프트 최적화**: $Few$-$shot$ 예제, $Chain$-$of$-$Thought$ (사고의 흐름) 프롬프팅 적용.
  * **캐싱 메커니즘 구현**: 질의와 응답을 캐싱하여 $LLM$ 호출 중복 방지 및 비용 절감.

#### 6.4.2. 중기 계획 (3개월 이내)

  * **한국어 특화 모델 파인튜닝**: 입찰 공고 도메인 한국어 코퍼스를 활용하여 $LLaMA, Mistral, Solar$ 등 오픈소스 $LLM$을 파인튜닝.
  * **DB 마이그레이션**: $SQLite$에서 $PostgreSQL$로 마이그레이션하여 확장성 확보.
  * **FAISS 인덱스 업그레이드**: $IndexIVFFlat$ 또는 $IndexHNSW$ 적용을 통한 대규모 벡터 검색 성능 최적화.
  * **멀티모달 지원**: $GPT$-$4V$ 또는 $LLaVA$ 모델 통합, $OCR$ 및 표 구조 인식을 통해 이미지와 표 데이터 처리.
  * **보안 기능 구현**: $OAuth$ $2.0$ 기반 인증, $RBAC$, $API$ 키 보호, 감사 로깅 구현.

#### 6.4.3. 장기 계획 (6개월 이상)

  * **자동 문서 업데이트 시스템 구축**: 나라장터 $API$ 연동, 스케줄러를 통한 공고 자동 수집 및 임베딩 업데이트.
  * **대화형 분석 도구 개발**: 자연어 질의를 $SQL$ 또는 $Python$ 코드로 변환하여 데이터 탐색 및 시각화 기능 제공.
  * **추천 시스템 통합**: 사용자의 질의 및 관심 분야를 학습하여 새로운 공고를 능동적으로 추천.
  * **엔터프라이즈 기능**: 팀 단위 협업, 워크플로우 자동화, 대시보드 제공 등 조직 차원의 사용 지원.

-----

### 6.5. 감사의 말

본 프로젝트는 코드잇 $AI$ 4기 교육 과정의 일환으로 수행되었으며, 교육팀의 체계적인 커리큘럼, 멘토님들의 기술적 조언, 그리고 팀원들의 전문성과 헌신 덕분에 성공적으로 마무리될 수 있었습니다.

  * **팀원들의 헌신**:
      * 신승목님 (데이터 엔지니어): 견고한 데이터 파이프라인 및 $DB$ 구축.
      * 김명환님 (머신러닝 엔지니어): 임베딩 처리, $FAISS$ 인덱스 최적화, 다단계 검색 시스템 완성.
      * 이민규님 (AI 리서처): $LLM$ 통합, 프롬프트 엔지니어링, 평가 시스템 구축.
      * 오형주님 (프론트엔드 엔지니어): $Streamlit$ 기반 $UI$ 개발 및 모든 모듈 통합.

오픈소스 커뮤니티와 도구를 제공한 개발자들에게 깊은 감사를 표하며, 본 프로젝트가 $RAG$ 시스템 구축을 고민하는 이들에게 기여하고 $AI$ 기술 민주화에 보탬이 되기를 바랍니다.

-----
