---
layout: default
title: "[중급프로젝트] RAG 기반 정부나라장터 입찰공고 분석 시스템 - 사용자 인터페이스 및 시스템 통합"
description: "[중급프로젝트] RAG 기반 정부나라장터 입찰공고 분석 시스템 - 사용자 인터페이터 및 시스템 통합"
date: 2025-11-25
cache-control: no-cache
expires: 0
pragma: no-cache
author: "오형주 (프론트엔드 엔지니어)"
---

## 5. 사용자 인터페이스 및 시스템 통합 (오형주)

### 5.1. Streamlit 기반 UI 설계

#### 5.1.1. 페이지 구조 및 레이아웃

Streamlit은 데이터 과학 애플리케이션을 위한 오픈소스 프레임워크로, Python 코드만으로 웹 인터페이스를 신속하게 구축할 수 있습니다. 본 시스템은 Streamlit을 선택하여 개발 생산성을 극대화하고 사용자에게 직관적인 인터페이스를 제공합니다.

애플리케이션의 페이지 구조는 단일 페이지 형태로 설계되었습니다. 상단에는 시스템 제목과 간단한 설명이 표시되며, 사용자가 현재 어떤 시스템을 사용하고 있는지 즉시 파악할 수 있도록 합니다. 제목은 set_page_config 메서드를 통해 브라우저 탭에도 표시되어 여러 탭을 사용하는 환경에서 식별이 용이합니다.

사이드바는 주요 설정과 제어 기능을 담당합니다. Streamlit의 sidebar 컴포넌트를 활용하여 화면 왼쪽에 고정된 영역을 생성하고, 이곳에 세션 관리, 검색 옵션, 고급 설정 등을 배치합니다. 사이드바를 사용함으로써 메인 화면은 대화 내용에 집중할 수 있고, 설정 변경이 필요할 때만 사이드바를 참조하는 효율적인 레이아웃을 구현합니다.

메인 영역은 채팅 인터페이스로 구성됩니다. 사용자 메시지와 어시스턴트 응답이 시간순으로 표시되며, 카카오톡이나 슬랙과 같은 익숙한 메신저 형태를 따릅니다. Streamlit의 chat_message 컴포넌트는 역할에 따라 자동으로 아이콘과 스타일을 적용하여 누가 말하는지 명확히 구분됩니다. 사용자 메시지는 오른쪽 정렬되고, 어시스턴트 메시지는 왼쪽 정렬되어 대화의 흐름을 시각적으로 표현합니다.

입력 영역은 화면 하단에 고정되어 있습니다. chat_input 컴포넌트를 사용하여 텍스트 입력창을 제공하며, 엔터 키를 누르면 즉시 메시지가 전송됩니다. 플레이스홀더 텍스트로 입찰 공고에 대해 질문해주세요와 같은 안내 문구를 표시하여 사용자가 무엇을 입력해야 하는지 직관적으로 알 수 있도록 합니다.

반응형 디자인은 Streamlit이 기본적으로 제공하는 기능을 활용합니다. 화면 크기에 따라 사이드바가 자동으로 접히거나 펼쳐지며, 모바일 환경에서도 사용 가능한 레이아웃을 유지합니다. 다만 입찰 공고 분석은 상당한 텍스트 양을 다루므로 데스크톱 환경을 주요 사용 환경으로 가정하고 최적화하였습니다.

#### 5.1.2. 채팅 인터페이스 구현

채팅 인터페이스는 RAG 시스템과 사용자 간의 주요 상호작용 지점입니다. 자연스러운 대화 경험을 제공하기 위해 여러 UX 패턴을 적용하였습니다.

메시지 표시는 session_state를 활용하여 구현됩니다. Streamlit은 페이지가 새로고침될 때마다 전체 스크립트를 재실행하는 특성이 있어, 상태를 유지하기 위해 session_state가 필수적입니다. messages 키에 대화 이력을 리스트 형태로 저장하고, 각 메시지는 role과 content 필드를 포함하는 딕셔너리입니다. 페이지 렌더링 시 이 리스트를 순회하며 chat_message 컴포넌트로 각 메시지를 표시합니다.

스트리밍 응답은 사용자 경험을 크게 향상시킵니다. LLM이 답변을 생성하는 동안 완료될 때까지 기다리는 대신, 토큰이 생성되는 즉시 화면에 표시합니다. OpenAI API의 Streaming 기능을 활용하여 답변이 생성되는 과정을 볼 수 있어 사용자가 시스템이 작동 중임을 인지하고, 긴 답변의 경우에도 지루함을 느끼지 않습니다.

로딩 인디케이터는 시스템이 작업 중임을 명확히 알립니다. 검색을 수행하거나 LLM 응답을 기다리는 동안 spinner 컴포넌트를 표시하여 사용자가 시스템이 멈춘 것으로 오해하지 않도록 합니다. 로딩 메시지는 현재 수행 중인 작업을 설명하여 더욱 명확한 피드백을 제공합니다. 예를 들어 관련 문서를 검색하는 중입니다 또는 답변을 생성하는 중입니다와 같은 메시지를 표시합니다.

에러 처리는 사용자 친화적으로 구현되었습니다. API 호출 실패나 예상치 못한 오류가 발생하면 error 컴포넌트를 사용하여 빨간색 경고 상자를 표시합니다. 오류 메시지는 기술적 세부사항을 숨기고 사용자가 이해할 수 있는 언어로 작성됩니다. 예를 들어 OpenAI API 키가 설정되지 않았습니다. 사이드바에서 API 키를 입력해주세요와 같이 구체적인 해결 방법을 안내합니다.

메시지 히스토리 스크롤은 자동으로 관리됩니다. 새로운 메시지가 추가되면 화면이 자동으로 최하단으로 스크롤되어 사용자가 항상 최신 메시지를 볼 수 있습니다. 다만 사용자가 의도적으로 위로 스크롤하여 이전 메시지를 확인하는 경우에는 자동 스크롤을 억제하여 읽기를 방해하지 않습니다.

메시지 컨텍스트 메뉴는 추가 기능을 제공합니다. 각 메시지 옆에 작은 아이콘 버튼을 배치하여 복사, 출처 보기, 피드백 제공 등의 액션을 수행할 수 있습니다. 특히 출처 보기 기능은 어시스턴트 답변에 대해 어떤 문서에서 정보를 가져왔는지 보여주어 신뢰성을 높입니다.

#### 5.1.3. 세션 관리 UI

세션 관리는 사용자가 여러 대화를 조직하고 이전 대화로 돌아갈 수 있게 합니다. 사이드바의 상단 영역을 세션 관리 섹션으로 할당하여 항상 접근 가능하도록 하였습니다.

새 세션 생성은 버튼 하나로 간단히 수행됩니다. 새 대화 시작 버튼을 클릭하면 새로운 세션 ID가 생성되고, session_state의 messages 리스트가 초기화되며, 메인 화면이 비워집니다. 사용자는 이전 대화의 컨텍스트에 영향받지 않고 새로운 주제로 대화를 시작할 수 있습니다.

세션 목록은 접을 수 있는 expander 컴포넌트로 구현됩니다. 대화 기록 섹션을 클릭하면 저장된 세션들이 리스트 형태로 표시됩니다. 각 세션은 이름, 마지막 활동 시각, 메시지 수 등의 정보와 함께 표시되어 사용자가 원하는 대화를 쉽게 찾을 수 있습니다. 세션 이름은 기본적으로 시작 시각으로 자동 생성되지만, 사용자가 의미 있는 이름으로 변경할 수 있는 기능을 제공합니다.

세션 전환은 라디오 버튼이나 셀렉트박스를 통해 이루어집니다. 사용자가 세션을 선택하면 해당 세션의 ID가 session_state에 저장되고, ChatHistoryDB에서 해당 세션의 메시지를 불러와 화면에 표시합니다. 세션 전환 시 현재 세션의 상태는 자동으로 저장되어 나중에 돌아왔을 때 이어서 대화할 수 있습니다.

세션 삭제는 신중하게 처리됩니다. 각 세션 옆에 작은 삭제 버튼을 배치하되, 클릭 시 즉시 삭제되지 않고 확인 대화상자를 표시합니다. 정말 이 대화를 삭제하시겠습니까? 삭제된 대화는 복구할 수 없습니다와 같은 경고 메시지를 보여주어 실수로 인한 데이터 손실을 방지합니다.

활성 세션 표시는 사용자가 현재 어떤 대화를 보고 있는지 명확히 합니다. 세션 목록에서 현재 활성화된 세션은 하이라이트 색상으로 표시되고, 세션 이름 앞에 작은 아이콘을 추가하여 시각적으로 구분합니다. 이를 통해 사용자가 여러 세션을 오가며 작업할 때 혼란을 최소화합니다.

세션 통계는 정보성 패널로 제공됩니다. 사이드바 하단에 총 대화 수, 총 메시지 수, 평균 대화 길이 등의 통계를 표시하여 사용자가 시스템 사용 현황을 파악할 수 있게 합니다. 이러한 통계는 ChatHistoryDB의 get_chat_stats 메서드를 호출하여 실시간으로 계산됩니다.

### 5.2. 시스템 통합 아키텍처

#### 5.2.1. 모듈 간 데이터 흐름

RAG 시스템은 여러 독립적인 모듈이 유기적으로 연결되어 작동합니다. 각 모듈은 명확한 책임을 가지며, 정의된 인터페이스를 통해 통신하여 결합도를 낮추고 유지보수성을 높입니다.

사용자 질의 흐름은 다음과 같이 진행됩니다. 사용자가 Streamlit UI에 질문을 입력하면 app.py의 이벤트 핸들러가 이를 수신합니다. 질의 텍스트는 먼저 Retrieval 모듈로 전달되어 관련 문서 검색이 수행됩니다. Retrieval은 내부적으로 VectorStoreManager를 호출하여 FAISS 인덱스에서 유사도 검색을 실행하고, 상위 청크를 추출합니다. 검색 결과는 딕셔너리 형태로 반환되며, 각 청크의 텍스트와 메타데이터를 포함합니다.

검색 결과는 LLMProcessor로 전달됩니다. LLMProcessor는 검색된 청크를 포맷하여 프롬프트 컨텍스트를 구성하고, 사용자 질의와 함께 LLM에 전달합니다. OpenAI API를 통해 LLM이 응답을 생성하면, 이를 받아 후처리하고 최종 답변 텍스트를 반환합니다. 동시에 LLMProcessor는 ChatHistoryDB를 호출하여 질의와 응답을 데이터베이스에 기록합니다.

답변은 app.py로 반환되어 Streamlit UI를 통해 사용자에게 표시됩니다. 이 과정에서 스트리밍이 활성화되어 있으면 토큰 단위로 실시간 렌더링이 수행되고, 비활성화되어 있으면 완성된 답변 전체가 한 번에 표시됩니다. 표시와 동시에 session_state에 메시지가 추가되어 대화 이력이 유지됩니다.

데이터 변환은 각 모듈 경계에서 발생합니다. Retrieval의 출력은 리스트 형태의 딕셔너리이지만, LLMProcessor는 이를 문자열 형태의 컨텍스트로 변환합니다. 이러한 변환 로직은 각 모듈 내부에 캡슐화되어 있어, 한쪽 모듈의 내부 구현이 변경되어도 인터페이스만 유지되면 다른 모듈에 영향을 주지 않습니다.

에러 전파는 계층적으로 처리됩니다. 하위 모듈에서 발생한 예외는 상위 모듈로 전파되며, 각 계층은 필요한 로깅을 수행하고 적절히 재발생시킵니다. 최종적으로 app.py에서 모든 예외를 포착하여 사용자에게 친화적인 오류 메시지로 변환하여 표시합니다. 이를 통해 시스템 내부의 기술적 오류가 사용자에게 직접 노출되지 않습니다.

비동기 처리는 필요한 부분에서 선택적으로 적용됩니다. LLM 응답 생성은 수 초가 소요될 수 있으므로, 이 동안 UI가 블로킹되지 않도록 Streamlit의 비동기 메커니즘을 활용합니다. 다만 Python의 GIL 특성상 완전한 병렬 처리는 제한적이며, 주로 I/O 바운드 작업에서 효과를 발휘합니다.

#### 5.2.2. Config 기반 설정 관리

시스템의 모든 설정은 Config 클래스를 통해 중앙 집중식으로 관리됩니다. 이를 통해 설정 변경이 필요할 때 여러 파일을 수정할 필요 없이 단일 지점에서 관리할 수 있습니다.

Config 클래스는 싱글톤 패턴으로 구현되어 애플리케이션 전체에서 동일한 인스턴스를 공유합니다. 최초 임포트 시 JSON 설정 파일을 로드하여 인스턴스를 생성하고, 이후 모든 모듈은 이 인스턴스를 참조합니다. 싱글톤 패턴은 설정의 일관성을 보장하고, 메모리 사용을 최소화하며, 설정 변경 시 전체 시스템에 즉시 반영되도록 합니다.

설정 파일은 JSON 형식으로 작성되어 가독성과 편집 용이성을 제공합니다. 계층적 구조를 사용하여 관련된 설정을 그룹화하고, 각 설정에 대한 주석을 별도 필드로 포함하여 의미를 명확히 합니다. 예를 들어 embedding 섹션 아래에 model, batch_size, chunk_size 등의 설정이 그룹화되어 있습니다.

기본값은 Config 클래스 내부에 하드코딩되어 있습니다. JSON 파일이 존재하지 않거나 특정 키가 누락된 경우, 미리 정의된 기본값을 사용하여 시스템이 정상적으로 작동하도록 보장합니다. 이를 통해 초기 설정 과정을 단순화하고, 사용자가 모든 설정을 명시하지 않아도 합리적인 기본값으로 시스템을 실행할 수 있습니다.

동적 설정 변경은 제한적으로 지원됩니다. 대부분의 설정은 애플리케이션 시작 시 로드되어 고정되지만, 일부 설정은 런타임에 변경 가능합니다. 예를 들어 검색에 사용할 top_k 값을 UI를 통해 동적으로 조정할 수 있으며, 변경 즉시 다음 질의부터 적용됩니다.

환경 변수 오버라이드 기능은 배포 환경의 유연성을 제공합니다. 민감한 정보인 OpenAI API 키는 환경 변수로 제공하는 것이 보안상 바람직합니다. Config 클래스는 특정 설정에 대해 환경 변수를 우선적으로 확인하고, 존재하면 JSON 설정을 무시하고 환경 변수 값을 사용합니다. 이를 통해 개발 환경과 프로덕션 환경에서 서로 다른 설정을 쉽게 적용할 수 있습니다.

설정 검증은 애플리케이션 시작 시 수행됩니다. 필수 설정이 누락되었거나 값이 유효하지 않은 경우 명확한 오류 메시지와 함께 시작을 중단합니다. 예를 들어 chunk_size가 음수이거나 너무 큰 값으로 설정된 경우 경고를 출력하고 기본값으로 대체합니다. 이러한 검증은 설정 오류로 인한 런타임 에러를 사전에 방지합니다.

#### 5.2.3. 로깅 및 모니터링

시스템의 동작을 추적하고 문제를 진단하기 위해 포괄적인 로깅 체계를 구축하였습니다. Python의 logging 모듈을 활용하여 구조화된 로그를 생성하고, 레벨에 따라 적절히 필터링합니다.

로그 레벨은 중요도에 따라 5단계로 구분됩니다. DEBUG 레벨은 상세한 개발 정보를 기록하며 프로덕션에서는 비활성화됩니다. INFO 레벨은 정상적인 작업 진행 상황을 기록합니다. WARNING 레벨은 잠재적 문제나 예상치 못한 상황을 기록합니다. ERROR 레벨은 작업 실패나 예외를 기록합니다. CRITICAL 레벨은 시스템 전체에 영향을 주는 심각한 문제를 기록합니다.

로그 포맷은 일관된 구조를 가지고 있습니다. 타임스탬프, 로그 레벨, 모듈명, 함수명, 메시지로 구성되며, 각 필드는 명확히 구분됩니다. 타임스탬프는 KST 타임존으로 표시되어 한국 사용자가 시간을 직관적으로 이해할 수 있습니다. 예를 들어 2025-11-25 14:30:45 KST | INFO | retrieval.search | 검색 쿼리 실행: 중이온 가속기와 같은 형식입니다.

파일 로깅은 RotatingFileHandler를 사용하여 구현됩니다. 로그 파일이 일정 크기를 초과하면 자동으로 백업 파일로 회전되고 새로운 파일이 생성됩니다. 최대 5개의 백업 파일을 유지하여 디스크 공간을 제어하면서도 충분한 이력을 보존합니다. 로그 파일은 logs 디렉토리에 날짜별로 저장되어 특정 기간의 로그를 쉽게 찾을 수 있습니다.

콘솔 로깅은 개발 환경에서 실시간 피드백을 제공합니다. StreamHandler를 사용하여 표준 출력으로 로그를 전송하며, 색상 코딩을 적용하여 레벨을 시각적으로 구분합니다. ERROR와 CRITICAL은 빨간색으로, WARNING은 노란색으로, INFO는 기본 색상으로 표시되어 중요한 로그를 즉시 인지할 수 있습니다.

성능 로깅은 각 주요 작업의 실행 시간을 측정하여 기록합니다. 검색 수행, 임베딩 생성, LLM 응답 생성 등의 작업에 대해 시작과 종료를 로깅하고, 소요 시간을 계산하여 기록합니다. 이를 통해 성능 병목 지점을 식별하고 최적화 대상을 결정할 수 있습니다.

에러 로깅은 예외 정보를 상세히 기록합니다. except 블록에서 logging.exception 메서드를 사용하여 스택 트레이스를 포함한 전체 예외 정보를 기록합니다. 이를 통해 문제 발생 시 원인을 빠르게 파악하고 재현할 수 있습니다. 또한 사용자 입력, 시스템 상태 등 컨텍스트 정보도 함께 기록하여 디버깅을 용이하게 합니다.

로그 분석 도구는 별도로 제공되지 않지만, 구조화된 로그 형식 덕분에 표준 Unix 도구나 Python 스크립트로 쉽게 분석할 수 있습니다. 예를 들어 grep, awk, sed 등을 사용하여 특정 패턴을 검색하거나, pandas를 사용하여 로그를 데이터프레임으로 로드하고 통계를 계산할 수 있습니다.

### 5.3. 추가 기능

#### 5.3.1. Top-K 파라미터 조정

Top-K는 검색 결과로 반환할 청크의 개수를 지정하는 파라미터입니다. 이 값은 검색 품질과 응답 생성 비용 간의 균형을 결정하므로, 사용자가 조정할 수 있도록 하였습니다.

#### 5.3.2. 문서 업로드 및 인덱싱

사용자가 직접 PDF 문서를 업로드하여 시스템에 추가할 수 있는 기능을 제공합니다. 이를 통해 공공 데이터포털의 문서뿐만 아니라 사용자가 보유한 입찰 문서도 분석 대상에 포함시킬 수 있습니다.

파일 업로더는 Streamlit의 file_uploader 컴포넌트를 사용합니다. PDF와 HWP 파일만 허용하도록 accept_multiple_files와 type 파라미터를 설정하고, 파일 선택 버튼을 통해 업로드할 수 있습니다. 업로드된 파일은 UploadedFile 객체로 반환되며, 파일명, 크기, 내용 등에 접근할 수 있습니다.

중복 검사는 업로드 즉시 수행됩니다. 파일 내용의 SHA-256 해시를 계산하고, DocumentsDB에서 동일한 해시를 가진 문서가 있는지 확인합니다. 중복이 감지되면 업로드를 중단하고 이미 존재하는 문서입니다라는 메시지를 표시합니다. 사용자는 중복 업로드를 강제할 수 있는 옵션을 체크박스로 제공받으며, 이 경우 기존 문서를 덮어쓸지 새 버전으로 추가할지 선택할 수 있습니다.

문서 처리 파이프라인은 자동으로 실행됩니다. PDF를 Markdown으로 변환하고, 페이지 마커를 삽입하며, 전처리를 수행하고, DocumentsDB에 저장하는 전체 과정이 순차적으로 진행됩니다. 각 단계는 progress 컴포넌트를 통해 진행 상황을 시각적으로 표시하여 사용자가 대기 시간 동안 시스템 상태를 파악할 수 있습니다.

임베딩 생성은 선택 사항으로 제공됩니다. 문서가 DocumentsDB에 저장된 후, 즉시 임베딩을 생성하여 FAISS 인덱스에 추가할지 나중에 수행할지 선택할 수 있습니다. 즉시 생성을 선택하면 대기 시간이 길어지지만 바로 검색 가능하고, 나중에 수행을 선택하면 업로드는 빠르지만 배치 임베딩 작업을 별도로 실행해야 합니다.

오류 처리는 친절하게 구현되었습니다. 파일이 손상되어 PDF 파싱이 실패하거나, 페이지가 너무 많아 처리 시간이 초과되거나, API 호출이 실패하는 등의 문제가 발생하면 명확한 오류 메시지를 표시합니다. 부분적으로 처리된 데이터는 롤백되어 데이터베이스 일관성을 유지하며, 사용자는 문제를 해결한 후 재시도할 수 있습니다.

업로드 이력은 별도 패널에 표시됩니다. 사용자가 업로드한 모든 문서의 목록을 시간순으로 보여주며, 각 문서의 처리 상태, 페이지 수, 파일 크기, 업로드 시각 등의 정보를 제공합니다. 문서를 클릭하면 상세 정보를 보거나 삭제할 수 있는 액션을 수행할 수 있습니다.

#### 5.3.3. 검색 결과 시각화

검색 결과를 단순히 텍스트로 나열하는 것을 넘어, 시각적으로 풍부한 정보를 제공하여 사용자가 결과를 쉽게 이해하고 탐색할 수 있도록 합니다.

청크 카드는 각 검색 결과를 시각적 단위로 표현합니다. Streamlit의 expander 컴포넌트를 사용하여 접을 수 있는 카드 형태로 구현하고, 카드 헤더에는 문서명, 페이지 번호, 유사도 점수를 표시합니다.

유사도 점수 시각화는 막대 그래프 형태로 제공됩니다. 각 청크의 유사도를 0에서 1로 정규화하고, 길이가 다른 색상 막대로 표현합니다. 높은 유사도는 초록색, 중간은 노란색, 낮은 유사도는 빨간색으로 표시하여 결과의 품질을 직관적으로 파악할 수 있습니다.

문서 분포 차트는 검색 결과가 어떤 문서에서 왔는지 보여줍니다. 파이 차트나 막대 차트를 사용하여 각 문서별로 몇 개의 청크가 검색되었는지 표시하고, 클릭하면 해당 문서의 청크만 필터링하여 볼 수 있습니다. 이를 통해 특정 문서에 정보가 집중되어 있는지, 여러 문서에 분산되어 있는지 파악할 수 있습니다.

---
