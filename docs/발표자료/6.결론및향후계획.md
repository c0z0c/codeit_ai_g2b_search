---
layout: default
title: "[중급프로젝트] RAG 기반 정부나라장터 입찰공고 분석 시스템 - 결론 및 향후 계획"
description: "[중급프로젝트] RAG 기반 정부나라장터 입찰공고 분석 시스템 - 결론 및 향후 계획"
date: 2025-11-25
cache-control: no-cache
expires: 0
pragma: no-cache
author: "코드잇 AI 4기 PEP 팀"
---

## 6. 결론 및 향후 계획

### 6.1. 프로젝트 성과

본 프로젝트는 2025년 11월 10일부터 28일까지 3주간 진행된 RAG 기반 정부나라장터 입찰공고 분석 시스템 개발 과정이었습니다. 코드잇 AI 4기 PEP 팀은 데이터 엔지니어, 머신러닝 엔지니어, AI 리서처, 프론트엔드 엔지니어로 구성된 4인의 팀원이 각자의 전문성을 발휘하여 완전히 작동하는 프로덕션 수준의 시스템을 구축하였습니다.

#### 6.1.1. 기술적 성과

시스템 아키텍처 측면에서 계층화된 설계를 성공적으로 구현하였습니다. 데이터 저장 계층은 SQLite 데이터베이스 3개로 구성되어 문서 원본, 임베딩 벡터, 대화 이력을 독립적으로 관리합니다. 데이터 접근 계층은 각 데이터베이스에 대응하는 관리 클래스를 제공하여 SQL 쿼리를 추상화하고 재사용 가능한 메서드를 노출합니다. 비즈니스 로직 계층은 문서 처리, 임베딩 생성, 검색, LLM 응답 생성 등 핵심 기능을 모듈화하여 구현하였습니다. 애플리케이션 계층은 app.py를 통해 전체 워크플로우를 조율하고 각 모듈을 통합합니다. 사용자 인터페이스 계층은 Streamlit을 활용하여 직관적이고 반응적인 웹 애플리케이션을 제공합니다. 이러한 계층 분리는 각 모듈의 독립적인 개발과 테스트를 가능하게 하였으며, 향후 확장과 유지보수의 기반이 되었습니다.

문서 처리 파이프라인은 완전 자동화되었습니다. PDF와 HWP 파일을 수집하여 SHA-256 해시 기반으로 중복을 검사하고, pymupdf4llm을 사용하여 Markdown으로 변환하며, 페이지 마커를 삽입하고, 3단계 전처리를 수행하여 DocumentsDB에 저장하는 전체 과정이 순차적으로 실행됩니다. 실제 운영에서 2건의 중복 문서를 성공적으로 감지하여 저장 공간과 임베딩 비용을 절감하였습니다. 전처리 과정에서 평균 21.5퍼센트의 토큰 절약을 달성하였으며, 이는 연간 약 15.3달러의 임베딩 비용 절감으로 이어집니다.

임베딩 및 벡터 저장소 구현은 확장 가능한 구조를 갖추었습니다. OpenAI text-embedding-3-small 모델을 사용하여 1536차원 벡터를 생성하고, FAISS IndexFlatL2 인덱스에 저장하여 정확한 최근접 이웃 검색을 보장합니다. 청킹 전략은 RecursiveCharacterTextSplitter를 활용하여 페이지 단위로 문서를 분할하고, 청크 크기 1500 토큰과 오버랩 300 토큰으로 컨텍스트를 보존합니다. 각 청크에는 포괄적인 메타데이터가 첨부되어 출처 추적, 재현성 보장, 실험 관리가 가능합니다. embedding_config_hash를 통해 설정 변경을 자동 감지하고 재임베딩을 트리거하여 데이터 일관성을 유지합니다.

다단계 검색 시스템은 정밀도와 재현율의 균형을 달성하였습니다. 1차 광범위 검색은 전체 데이터베이스를 대상으로 유사도 기반 검색을 수행하여 관련 문서를 식별합니다. 2차 심층 검색은 식별된 문서 내에서 file_hash 필터링을 적용하여 특정 문서의 상세 내용을 탐색합니다. 테스트 결과 2차 검색에서 무관한 질의에 대해 0건의 결과를 반환하여 노이즈 제거 효과가 입증되었으며, 관련 질의에 대해서는 정확한 위치 정보를 포함한 상세 답변을 생성하였습니다.

LLM 통합은 최신 모델을 활용하여 고품질 응답을 제공합니다. gpt-5-mini를 기본 모델로 채택하여 빠른 응답 속도와 낮은 비용을 실현하면서도 우수한 자연어 생성 능력을 확보하였습니다. 모델별 파라미터 호환성을 자동 처리하여 개발자가 의식하지 않아도 되도록 하였으며, temperature 제약이나 max_completion_tokens 사용 등의 차이를 투명하게 관리합니다. ConversationSummaryMemory를 구현하여 긴 대화에서도 토큰 한도를 준수하면서 컨텍스트를 유지하고, 한국어 요약 프롬프트를 최적화하여 자연스러운 한국어 대화 경험을 제공합니다.

평가 시스템은 객관적인 품질 측정을 가능하게 하였습니다. LLM Judge 기반 평가를 구현하여 Faithfulness, Context Relevance, Answer Accuracy, Answer Relevance의 4대 지표로 시스템 성능을 종합적으로 평가합니다. JSON 형식의 구조화된 결과 반환을 통해 자동화된 분석과 모니터링이 가능하며, 각 지표에 대한 Reasoning 필드는 평가 근거를 투명하게 제공하여 개선 방향을 명확히 합니다.

사용자 인터페이스는 직관성과 기능성을 동시에 달성하였습니다. Streamlit 기반의 웹 애플리케이션은 채팅 인터페이스를 통해 자연스러운 대화 경험을 제공하고, 세션 관리를 통해 여러 대화를 조직하며, 사이드바를 통해 검색 옵션과 고급 설정을 제어할 수 있습니다. 스트리밍 응답은 실시간으로 텍스트를 렌더링하여 사용자 경험을 향상시키고, 로딩 인디케이터는 시스템 상태를 명확히 알립니다. 문서 업로드 기능은 사용자가 직접 PDF를 추가하여 분석 범위를 확장할 수 있게 하며, 검색 결과 시각화는 청크 카드, 유사도 그래프, 문서 분포 차트 등을 통해 풍부한 정보를 제공합니다.

#### 6.1.2. 정량적 지표

시스템의 성능을 구체적인 수치로 정리하면 다음과 같습니다.

전처리 효율성 측면에서 원본 대비 평균 21.5퍼센트의 토큰 절약을 달성하였습니다. 이는 공백과 개행 정리로 15.4퍼센트, Markdown 요소 제거로 23.3퍼센트, 빈 테이블 행 제거로 47.4퍼센트의 절감 효과가 누적된 결과입니다. 실제 사례에서 원본 36,146자가 전처리 후 28,359자로 축소되었으며, 평균 9,036 토큰에서 7,089 토큰으로 감소하였습니다.

비용 절감 효과는 문서당 0.000193달러의 임베딩 비용 절감으로 나타났습니다. 전처리 전 문서당 0.000902달러에서 전처리 후 0.000709달러로 감소하여 21.5퍼센트의 비용 절감을 실현하였습니다. 연간 79,200건을 처리한다고 가정하면 약 15.3달러의 직접 비용 절감이 발생하며, LLM 응답 생성에서의 간접 비용 절감까지 고려하면 효과는 더욱 커집니다.

중복 제거 성과는 2건의 중복 문서를 감지하고 제거하여 저장 공간과 임베딩 비용을 절약하였습니다. 해시 20cdb1e7로 시작하는 BioIN 의료기기산업 관련 문서와 해시 fe07779f로 시작하는 국가과학기술지식정보서비스 관련 문서가 중복으로 식별되었습니다. 중복당 수백 킬로바이트에서 수 메가바이트의 저장 공간 절약과 문서당 약 0.002달러의 임베딩 비용 절감이 이루어졌습니다.

검색 성능 지표는 테스트를 통해 검증되었습니다. 1차 광범위 검색에서 평균 5개의 청크를 0.5초 이내에 반환하였으며, 상위 결과의 유사도 점수는 평균 0.3에서 0.5 사이로 적절한 관련성을 보였습니다. 2차 심층 검색에서는 file_hash 필터링을 통해 무관한 질의에 대해 0건의 결과를 반환하여 완벽한 노이즈 제거를 달성하였고, 관련 질의에 대해서는 2개의 정확한 결과를 반환하였습니다.

응답 생성 시간은 gpt-5-mini 모델을 사용하여 평균 2초에서 5초 사이에 완료되었습니다. 짧은 답변은 2초 이내, 중간 길이 답변은 3초에서 4초, 긴 답변은 5초 내외로 측정되었습니다. 스트리밍 응답을 활성화하면 첫 토큰이 0.5초 이내에 표시되어 사용자는 즉각적인 피드백을 받을 수 있습니다.

데이터베이스 성능은 SQLite의 효율성을 입증하였습니다. DocumentsDB는 수십 건의 문서를 수 밀리초 이내에 조회하고, 중복 검사는 해시 인덱스를 활용하여 즉시 완료됩니다. ChatHistoryDB는 세션당 수백 개의 메시지를 저장하고 조회하는 데 10밀리초 이내의 응답 시간을 보였습니다. FAISS 인덱스는 수천 개의 벡터에 대해 최근접 이웃 검색을 10밀리초에서 50밀리초 사이에 수행하였습니다.

### 6.2. 핵심 인사이트

프로젝트를 진행하며 발견한 중요한 통찰과 교훈을 정리합니다.

#### 6.2.1. RAG 시스템 설계 원칙

RAG 시스템의 성공은 각 단계의 품질이 누적되어 결정됩니다. 문서 수집 단계에서 중복을 제거하고 메타데이터를 정확히 추출하는 것이 후속 단계의 품질을 좌우합니다. 전처리 단계에서 노이즈를 제거하면서도 의미를 보존하는 균형이 중요하며, 과도한 전처리는 오히려 정보 손실을 초래할 수 있습니다. 청킹 전략은 문서의 구조와 도메인 특성을 고려해야 하며, 일률적인 크기 분할보다는 페이지 경계나 의미 단위를 존중하는 접근이 효과적입니다. 검색 단계는 단일 전략보다 다단계 접근이 우수한 결과를 제공하며, 1차 검색으로 후보를 좁히고 2차 검색으로 정밀도를 높이는 방식이 효율적입니다. 응답 생성 단계는 프롬프트 엔지니어링이 핵심이며, 명확한 역할 정의와 구조화된 컨텍스트 제공이 일관된 품질을 보장합니다.

계층화된 아키텍처는 복잡한 시스템을 관리 가능하게 만듭니다. 각 계층이 명확한 책임을 가지고 정의된 인터페이스를 통해 통신하면, 한 계층의 변경이 다른 계층에 영향을 주지 않습니다. 예를 들어 DocumentsDB의 내부 스키마를 변경하더라도 메서드 시그니처를 유지하면 상위 계층은 영향을 받지 않습니다. 이러한 느슨한 결합은 병렬 개발을 가능하게 하고, 팀원들이 독립적으로 작업하면서도 통합 시점에 문제를 최소화합니다.

메타데이터의 중요성은 아무리 강조해도 지나치지 않습니다. 파일 해시, 청크 해시, 설정 해시는 재현성을 보장하고 중복을 방지하며 자동 재처리를 가능하게 합니다. 페이지 번호, 청크 인덱스, 타임스탬프는 출처 추적과 버전 관리를 지원합니다. 임베딩 모델명, 청킹 설정, 전처리 옵션은 실험 관리와 비교 분석을 용이하게 합니다. 초기에 메타데이터 구조를 신중히 설계하고 일관되게 유지하는 것이 장기적인 시스템 품질을 결정합니다.

한국어 처리는 영어 중심 도구의 한계를 인식하고 적절히 대응해야 합니다. OpenAI 모델은 한국어를 지원하지만 영어에 비해 성능이 낮을 수 있으므로, 프롬프트를 한국어로 작성하고 명시적인 언어 지시를 포함하는 것이 중요합니다. 토크나이저는 한국어 텍스트를 과도하게 분할하는 경향이 있어, 청크 크기를 설정할 때 이를 고려하여 영어 대비 20퍼센트에서 30퍼센트 더 큰 값을 사용하는 것이 적절합니다. 용어 일관성은 도메인 특화 사전을 구축하거나 프롬프트에 용어 목록을 포함하여 개선할 수 있습니다.

#### 6.2.2. 팀 협업 및 프로젝트 관리

명확한 역할 분담은 효율적인 협업의 기반입니다. 데이터 엔지니어는 문서 수집과 데이터베이스 설계에 집중하고, 머신러닝 엔지니어는 임베딩과 벡터 저장소를 담당하며, AI 리서처는 LLM 통합과 프롬프트 최적화를 맡고, 프론트엔드 엔지니어는 UI와 시스템 통합을 책임지는 구조는 각자의 전문성을 최대한 활용하게 합니다. 다만 역할 경계가 너무 엄격하면 통합 시점에 문제가 발생할 수 있으므로, 정기적인 동기화와 크로스 리뷰가 필요합니다.

인터페이스 우선 설계는 통합을 원활하게 합니다. 프로젝트 초기에 각 모듈의 인터페이스를 문서화하고 합의하면, 팀원들이 실제 구현을 완료하기 전에도 통합을 시뮬레이션하고 테스트할 수 있습니다. 더미 구현이나 목 객체를 사용하여 인터페이스를 검증하고, 필요시 조기에 수정하는 것이 후반부 재작업을 줄입니다.

점진적 통합은 위험을 분산시킵니다. 모든 모듈이 완성될 때까지 기다렸다가 한 번에 통합하는 빅뱅 방식은 문제 발생 시 원인 파악이 어렵고 일정 지연 위험이 큽니다. 대신 주차별로 완성된 모듈을 통합하고 엔드투엔드 테스트를 수행하면, 문제를 조기에 발견하고 점진적으로 해결할 수 있습니다. 본 프로젝트에서는 Week 1에 더미 데이터와 프로토타입으로 전체 플로우를 검증하고, Week 2에 실제 구현을 통합하며, Week 3에 최적화와 문서화를 수행하는 전략이 성공적이었습니다.

문서화는 협업의 비용을 절감합니다. 각 모듈의 인터페이스, 설정 옵션, 사용 예제를 문서화하면 팀원 간 질문이 줄어들고 독립적인 작업이 가능해집니다. 본 프로젝트는 01_config_interface.md부터 06_logging_config.md까지 6개의 인터페이스 문서를 작성하여 모든 팀원이 참조할 수 있도록 하였습니다. 코드 주석과 Docstring도 충실히 작성하여 타입 힌트와 함께 제공하면, IDE의 자동완성과 타입 체크 기능이 개발 생산성을 크게 향상시킵니다.

#### 6.2.3. 기술 선택의 트레이드오프

OpenAI 모델 의존성은 양날의 검입니다. OpenAI API는 강력한 성능과 간편한 사용성을 제공하지만, 외부 서비스 의존성으로 인한 가용성 위험과 비용 증가 가능성이 존재합니다. API 장애나 속도 제한은 시스템 전체에 영향을 미치며, 토큰 가격 인상은 운영 비용을 직접적으로 증가시킵니다. 이러한 위험을 완화하기 위해 자동 재시도 로직과 에러 처리를 구현하였고, 향후 오픈소스 모델로의 전환 가능성을 염두에 두고 LangChain 추상화를 활용하였습니다.

SQLite 선택은 초기 단계에 적합했지만 확장성 제약이 있습니다. SQLite는 별도 서버 없이 파일 기반으로 작동하여 개발과 배포가 간단하고, 단일 사용자 환경에서 충분한 성능을 제공합니다. 그러나 동시 쓰기가 제한되고 대용량 데이터 처리에서 성능 저하가 발생할 수 있습니다. 프로덕션 환경으로 확장할 때는 PostgreSQL이나 MySQL로 마이그레이션을 고려해야 하며, 이를 위해 데이터베이스 접근 계층을 추상화하여 구현을 교체하기 쉽게 설계하였습니다.

FAISS IndexFlatL2는 정확성을 보장하지만 확장성이 제한적입니다. 완전 탐색 방식으로 모든 벡터를 비교하므로 정확한 최근접 이웃을 찾지만, 벡터 수가 증가하면 검색 시간이 선형적으로 증가합니다. 수만 개 이상의 벡터를 다루려면 IndexIVFFlat이나 IndexHNSW와 같은 근사 검색 알고리즘으로 전환해야 합니다. 이들은 약간의 정확도를 희생하여 대폭적인 속도 향상을 제공하며, 대부분의 실용적 응용에서 충분한 품질을 유지합니다.

Streamlit은 빠른 프로토타이핑에 탁월하지만 커스터마이징이 제한적입니다. Python 코드만으로 웹 애플리케이션을 구축할 수 있어 개발 속도가 빠르고, 데이터 과학 워크플로우와 자연스럽게 통합됩니다. 그러나 세밀한 UI 제어나 복잡한 상태 관리가 어렵고, 대규모 사용자 환경에서 성능 문제가 발생할 수 있습니다. 본 프로젝트는 MVP 단계에 적합하지만, 상업적 배포를 위해서는 React나 Vue.js 기반의 커스텀 프론트엔드로 재구축하는 것이 바람직합니다.

### 6.3. 한계점 및 개선 과제

프로젝트를 완료하며 인식한 현재 시스템의 한계와 향후 개선이 필요한 영역을 정리합니다.

#### 6.3.1. 현재 시스템의 제약

검색 품질은 여전히 개선 여지가 있습니다. 단순한 유사도 기반 검색은 의미적으로 유사하지만 질의 의도와 맞지 않는 결과를 반환할 수 있습니다. 예를 들어 중이온 가속기 구축 비용은 얼마인가라는 질의에 대해 중이온 가속기의 기술 사양이 높은 유사도로 검색될 수 있지만, 실제로 필요한 정보는 예산 관련 내용입니다. 이러한 불일치를 해결하기 위해서는 의도 분류나 엔티티 인식을 추가하여 질의를 더 정교하게 이해해야 합니다.

한국어 처리 품질은 영어 대비 낮은 수준입니다. OpenAI 모델은 주로 영어 데이터로 훈련되었기 때문에 한국어 텍스트에서 미묘한 뉘앙스를 놓치거나 문법적으로 어색한 문장을 생성할 수 있습니다. 특히 전문 용어나 약어가 많은 입찰 공고 도메인에서는 이러한 문제가 두드러집니다. 한국어 특화 모델을 파인튜닝하거나 한국어 코퍼스로 추가 훈련하는 것이 근본적인 해결책이지만, 현재는 프롬프트 최적화로 부분적으로 대응하고 있습니다.

확장성은 데이터 규모 증가 시 병목이 될 수 있습니다. 현재 시스템은 수십 개의 문서와 수천 개의 청크를 처리하도록 설계되었으며, 소규모 데모와 테스트에서는 원활히 작동합니다. 그러나 실제 나라장터의 연간 수만 건의 공고를 처리하려면 데이터베이스, 벡터 저장소, 검색 알고리즘 모두에서 최적화가 필요합니다. 특히 SQLite는 동시 접근이 제한적이므로 멀티유저 환경에서는 성능 저하가 예상됩니다.

평가 체계는 자동화되었지만 실사용 데이터가 부족합니다. LLM Judge 기반 평가는 체계적이고 재현 가능하지만, 실제 사용자 피드백과 얼마나 일치하는지 검증되지 않았습니다. 소수의 테스트 질의로만 평가를 수행하였으며, 다양한 질의 유형과 난이도를 포괄하는 벤치마크 데이터셋이 필요합니다. 또한 평가 지표와 실제 사용자 만족도 간의 상관관계를 분석하여 지표의 타당성을 검증해야 합니다.

보안과 권한 관리는 구현되지 않았습니다. 현재 시스템은 단일 사용자 환경을 가정하며, 인증이나 권한 제어가 없습니다. 실제 배포 시에는 사용자 인증, 문서 접근 권한, API 키 보호, 감사 로깅 등의 보안 기능이 필수적입니다. 특히 입찰 공고는 민감한 사업 정보를 포함할 수 있으므로, 문서별 접근 제어와 로그 추적이 중요합니다.

비용 최적화는 제한적으로만 수행되었습니다. 전처리를 통해 토큰을 절약하고 중복을 제거하는 등의 기본적인 최적화를 적용하였지만, 더 공격적인 비용 절감 전략은 구현하지 못했습니다. 예를 들어 캐싱을 통해 동일한 질의에 대한 중복 LLM 호출을 방지하거나, 저렴한 모델로 사전 필터링을 수행한 후 복잡한 질의만 고성능 모델로 라우팅하는 하이브리드 접근이 가능합니다.

#### 6.3.2. 사용자 피드백 부재

실제 사용자 테스트는 수행되지 못했습니다. 프로젝트 기간 동안 팀 내부 테스트에만 의존하였으며, 실제 입찰 공고를 분석하는 실무자나 조달 담당자의 피드백을 받지 못했습니다. 개발자의 관점에서는 합리적으로 보이는 기능이 실사용자에게는 불편하거나 불필요할 수 있으며, 반대로 간과한 중요한 요구사항이 있을 수 있습니다. 향후 파일럿 사용자 그룹을 모집하여 실제 업무 환경에서 시스템을 사용하게 하고, 정성적 및 정량적 피드백을 수집해야 합니다.

UI/UX는 기능 중심으로 설계되었으며, 사용자 경험 최적화가 부족합니다. Streamlit의 기본 컴포넌트를 주로 사용하여 빠르게 개발하였지만, 세련된 디자인이나 직관적인 워크플로우를 구현하지 못했습니다. 예를 들어 검색 결과를 탐색하고 필터링하는 과정이 번거로우며, 문서 간 비교나 요약 기능이 부족합니다. 전문 UI/UX 디자이너와 협업하여 사용자 여정을 분석하고 페르소나를 정의하며 와이어프레임을 작성하는 과정이 필요합니다.

도메인 전문가의 검증이 이루어지지 않았습니다. 입찰 공고 분석은 조달 및 계약 관리의 전문 지식을 요구하는 분야입니다. 시스템이 생성한 답변이 도메인 규칙이나 관행에 부합하는지, 법률적으로 정확한지 검증하지 못했습니다. 잘못된 정보를 제공하면 사용자의 의사결정에 부정적 영향을 미칠 수 있으므로, 조달 전문가나 법률 자문을 받아 시스템 출력을 검토하고 개선해야 합니다.

### 6.4. 향후 개발 계획

프로젝트를 지속 발전시키기 위한 단계별 계획을 수립하였습니다.

#### 6.4.1. 단기 계획 (1개월 이내)

사용자 테스트를 통한 피드백 수집이 최우선 과제입니다. 5명에서 10명의 파일럿 사용자를 모집하여 실제 입찰 공고를 분석하는 작업을 수행하게 하고, 구조화된 설문과 인터뷰를 통해 사용성, 정확성, 유용성을 평가합니다. 사용자의 질의 로그와 만족도 평가를 수집하여 개선 우선순위를 결정합니다.

검색 품질 개선은 구체적인 지표를 바탕으로 진행됩니다. 하이브리드 검색을 구현하여 키워드 기반 검색과 의미 기반 검색을 결합하고, 재순위화 모델을 추가하여 1차 검색 결과를 질의 의도에 맞게 재정렬합니다. BM25와 같은 전통적인 검색 알고리즘을 도입하여 FAISS 결과와 앙상블하면 정밀도와 재현율을 동시에 향상시킬 수 있습니다.

프롬프트 최적화는 체계적인 실험을 통해 수행됩니다. 다양한 프롬프트 템플릿을 작성하고 A/B 테스트로 비교하여 최적 버전을 선택합니다. Few-shot 예제를 추가하여 LLM이 기대하는 출력 형식을 명확히 이해하도록 하고, Chain-of-Thought 프롬프팅을 적용하여 복잡한 질의에 대한 추론 품질을 높입니다.

캐싱 메커니즘을 구현하여 비용을 절감합니다. 질의와 응답을 로컬 캐시에 저장하고, 동일하거나 유사한 질의가 들어오면 LLM 호출 없이 캐시에서 반환합니다. 유사도 기반 캐시를 사용하면 완전히 동일하지 않아도 충분히 유사한 질의에 대해 캐시를 활용할 수 있습니다. 이를 통해 반복적인 질의에 대한 응답 시간을 대폭 단축하고 API 비용을 절감합니다.

문서화를 확충하여 시스템 이해도를 높입니다. 사용자 가이드를 작성하여 시스템 설치, 설정, 사용법을 단계별로 설명하고, 개발자 문서를 확장하여 각 모듈의 내부 구조와 확장 방법을 상세히 기술합니다. API 레퍼런스를 자동 생성하여 모든 클래스와 메서드의 시그니처와 설명을 제공합니다.

#### 6.4.2. 중기 계획 (3개월 이내)

한국어 특화 모델 파인튜닝을 수행하여 언어 품질을 향상시킵니다. 입찰 공고 도메인의 한국어 코퍼스를 수집하고, 질의-답변 쌍 데이터셋을 구축하여 오픈소스 LLM을 파인튜닝합니다. LLaMA, Mistral, Solar와 같은 모델을 후보로 평가하고, 파인튜닝 후 성능을 OpenAI 모델과 비교하여 적합성을 검증합니다. 자체 모델을 운영하면 외부 의존성을 줄이고 장기적으로 비용을 절감할 수 있습니다.

데이터베이스를 PostgreSQL로 마이그레이션하여 확장성을 확보합니다. 스키마를 재설계하여 관계형 무결성 제약을 강화하고, 인덱스를 최적화하여 쿼리 성능을 향상시킵니다. 연결 풀링과 쿼리 캐싱을 설정하여 동시 사용자를 지원하고, 정기적인 백업과 복구 절차를 수립하여 데이터 안정성을 보장합니다.

FAISS 인덱스를 근사 검색 알고리즘으로 업그레이드합니다. IndexIVFFlat을 적용하여 벡터를 클러스터로 분할하고 관련 클러스터만 검색하거나, IndexHNSW를 사용하여 계층적 그래프 구조로 빠른 근사 검색을 수행합니다. 정확도와 속도의 트레이드오프를 벤치마크하여 최적 설정을 도출하고, 백만 개 이상의 벡터에서도 밀리초 단위 응답 시간을 유지합니다.

멀티모달 지원을 추가하여 이미지와 표를 처리합니다. PDF에 포함된 다이어그램, 차트, 표를 추출하고, 비전 모델을 사용하여 이미지 내용을 텍스트로 변환합니다. GPT-4V나 LLaVA와 같은 멀티모달 모델을 통합하여 이미지를 이해하고 설명하는 기능을 구현합니다. 표 데이터는 구조화된 형태로 파싱하여 SQL 쿼리나 데이터 분석을 가능하게 합니다.

보안 기능을 구현하여 프로덕션 준비를 완료합니다. 사용자 인증을 추가하여 OAuth 2.0이나 SAML을 지원하고, 역할 기반 접근 제어를 구현하여 문서 수준 권한을 관리합니다. API 키와 비밀번호는 환경 변수나 비밀 관리 서비스에 저장하고, 민감한 로그 정보는 마스킹 처리합니다. 모든 API 호출과 데이터 접근을 감사 로그에 기록하여 추적 가능성을 확보합니다.

#### 6.4.3. 장기 계획 (6개월 이상)

자동 문서 업데이트 시스템을 구축하여 최신 공고를 지속적으로 반영합니다. 나라장터 API를 정기적으로 폴링하여 새로운 공고를 감지하고, 자동으로 다운로드하여 처리 파이프라인에 투입합니다. 스케줄러를 설정하여 매일 또는 매시간 업데이트를 수행하고, 변경된 공고를 감지하여 기존 임베딩을 업데이트합니다.

대화형 분석 도구를 개발하여 사용자가 데이터를 탐색하고 시각화할 수 있게 합니다. 자연어로 데이터 쿼리를 표현하면 SQL이나 Python 코드로 변환하여 실행하고, 결과를 차트나 표로 자동 생성합니다. 예를 들어 최근 3개월 간 예산 규모별 공고 분포를 보여줘라는 질의를 이해하고 적절한 시각화를 제공합니다.

추천 시스템을 통합하여 사용자에게 관련 공고를 능동적으로 제안합니다. 사용자의 과거 질의와 관심 분야를 학습하여 프로파일을 구축하고, 새로 등록된 공고 중 관련성이 높은 것을 자동으로 추천합니다. 협업 필터링이나 콘텐츠 기반 필터링을 적용하여 개인화된 추천을 제공하고, 사용자 피드백을 통해 지속적으로 개선합니다.

모바일 애플리케이션을 개발하여 접근성을 확대합니다. React Native나 Flutter를 사용하여 iOS와 Android 앱을 구축하고, 웹 버전과 동일한 기능을 제공하면서도 모바일 환경에 최적화된 UI를 구현합니다. 푸시 알림을 통해 새로운 추천 공고나 중요한 업데이트를 실시간으로 알리고, 오프라인 모드를 지원하여 네트워크 없이도 이전 검색 결과를 확인할 수 있게 합니다.

엔터프라이즈 기능을 추가하여 조직 차원의 사용을 지원합니다. 팀 단위 협업 기능을 구현하여 공고를 공유하고 댓글을 달며 공동으로 분석합니다. 워크플로우 자동화를 통해 특정 조건을 만족하는 공고가 등록되면 자동으로 담당자에게 할당하고 알림을 보냅니다. 대시보드를 제공하여 팀의 활동 현황, 분석한 공고 수, 평균 응답 시간 등의 지표를 시각화합니다.

### 6.5. 감사의 말

본 프로젝트는 코드잇 AI 4기 교육 과정의 일환으로 수행되었으며, 많은 분들의 도움과 지원이 있었기에 완성할 수 있었습니다.

먼저 코드잇 교육팀에게 감사드립니다. 체계적인 커리큘럼과 실전 중심의 프로젝트 기회를 제공하여 이론을 실무에 적용하는 경험을 쌓을 수 있었습니다. 멘토님들의 기술적 조언과 피드백은 프로젝트 방향을 설정하고 막힌 부분을 해결하는 데 큰 도움이 되었습니다.

팀원들에게 깊은 감사를 표합니다. 신승목님은 데이터 엔지니어로서 견고한 데이터 파이프라인과 데이터베이스를 구축하여 시스템의 기반을 마련하였습니다. 문서 수집부터 중복 검사, 전처리까지 전체 프로세스를 자동화하고 최적화하는 데 헌신하였습니다. 김명환님은 머신러닝 엔지니어로서 임베딩 처리와 벡터 저장소를 설계하고 구현하였습니다. 청킹 전략을 연구하고 FAISS 인덱스를 최적화하며 다단계 검색 시스템을 완성하여 높은 검색 품질을 실현하였습니다. 이민규님은 AI 리서처로서 LLM 통합과 프롬프트 엔지니어링을 담당하였습니다. 한국어 응답 품질을 높이고 대화 이력을 관리하며 평가 시스템을 구축하여 시스템의 지능을 구현하였습니다. 오형주님은 프론트엔드 엔지니어로서 사용자 인터페이스와 시스템 통합을 책임졌습니다. Streamlit 기반의 직관적인 UI를 개발하고 모든 모듈을 하나로 통합하여 완전히 작동하는 애플리케이션을 완성하였습니다.

각 팀원의 전문성과 헌신, 그리고 협업 정신이 어우러져 짧은 기간에도 불구하고 의미 있는 결과물을 만들어낼 수 있었습니다. 기술적 도전에 직면했을 때 함께 고민하고 해결책을 찾았으며, 서로의 작업을 존중하고 지원하는 분위기 속에서 즐겁게 프로젝트를 진행하였습니다.

마지막으로 오픈소스 커뮤니티에 감사드립니다. LangChain, FAISS, Streamlit, PyMuPDF 등 수많은 오픈소스 라이브러리와 도구가 없었다면 이 프로젝트는 불가능했을 것입니다. 이러한 도구를 개발하고 유지보수하는 개발자들의 노력에 경의를 표하며, 본 프로젝트도 오픈소스로 공개하여 커뮤니티에 기여하고자 합니다.

RAG 기술은 빠르게 발전하고 있으며, 입찰 공고 분석 외에도 법률 문서 검토, 의료 기록 분석, 고객 지원 자동화 등 다양한 분야에 적용될 수 있습니다. 본 프로젝트가 RAG 시스템 구축을 고민하는 분들에게 참고 자료가 되고, 나아가 공공 데이터 활용과 AI 기술 민주화에 작은 보탬이 되기를 바랍니다.

---
