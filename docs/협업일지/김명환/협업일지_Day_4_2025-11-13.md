---
layout: default
title: "협업일지 Day 4 (2025-11-13) - 코드잇 AI 4기 3팀 김명환"
description: "협업일지 Day 4 (2025-11-13) - 코드잇 AI 4기 3팀 김명환"
date: 2025-11-13
author: "김명환"
cache-control: no-cache
expires: 0
pragma: no-cache
---

# 일일 협업일지 - Day 4 (2025-11-13)

## [1] 기본 정보
**날짜**: 2025-11-13
**이름**: 김명환
**팀명**: 코드잇 AI 4기 3팀

---

## [2] 오늘 맡은 역할 및 구체적인 작업 내용
**답변**:
```
1. 시스템 아키텍처 설계서 업데이트 (v3.0)
   - EmbeddingsDB 제거 및 VectorStoreManager 기반 아키텍처로 전환
   - 데이터베이스 구조 단순화 (3개 DB → 2개 DB)
   - 모든 다이어그램 및 설명을 실제 구현 코드와 일치하도록 업데이트

2. VectorStoreManager 고도화
   - chunk_hash 기반 중복 관리 시스템 구현
   - chunk_map 자료구조 도입: (file_hash, chunk_index) → (faiss_idx, chunk_hash)
   - 중복 체크 로직: chunk_hash 비교를 통한 스마트 업데이트
   - 더미 데이터 자동 삭제 기능 추가

3. 유사도 점수 체계 변경
   - 기존: 정규화된 similarity 점수 (0~1)
   - 변경: FAISS L2 거리 값 직접 사용 (원본 메트릭 보존)
   - 설계 문서에 거리 기반 해석 가이드 추가

4. 마크다운 전처리 함수 개선 (clean_markdown_text)
   - config 기반 선택적 전처리 적용
   - 특수 블록 보호: 코드블록, 수식블록, 페이지마커
   - 25개 테스트 케이스 100% 통과

5. EmbeddingProcessor 페이지 단위 청킹 구현
   - 페이지 단위로 텍스트 병합 후 chunk_size 기준 분할
   - chunk_type 분류: single, merged, split
   - chunk_hash 생성 및 메타데이터 저장

6. DocumentsDB 검색 기능 강화
   - search_documents() 메서드 추가
   - 자동 타입 판별 (file_hash vs filename)
   - LIKE 검색 지원
```

---

## [3] 오늘 작업 완료도 체크 (하나만 체크)
- [ ] 0% (시작 못함)
- [ ] 25% (시작은 했지만 진척 없음)
- [ ] 50% (진행 중, 절반 이하)
- [x] 75% (거의 완료됨)
- [ ] 100% (완료 및 점검까지 완료)

**간단한 근거**:
```
- VectorStoreManager 고도화 완료 (중복 관리, chunk_map)
- 마크다운 전처리 함수 완성 및 테스트 100% 통과
- 시스템 아키텍처 설계서 v3.0 업데이트 완료
- 페이지 단위 청킹 로직 구현 완료
- 통합 테스트 및 최종 검증 단계 남음
```

---

## [4] 오늘 협업 중 제안하거나 피드백한 내용이 있다면?
**답변**:
```
1. 유사도 점수 체계 변경 제안
   - 정규화된 similarity 점수 대신 FAISS L2 거리 값 직접 사용
   - 원본 메트릭 보존으로 정보 손실 방지
   - 설계 문서에 거리 기반 해석 가이드 추가

2. 중복 관리 전략 개선
   - chunk_hash 기반 스마트 업데이트 로직 도입
   - 동일 내용 재처리 방지로 효율성 향상
   - chunk_map 자료구조로 O(1) 중복 체크 가능

3. 마크다운 전처리 설정 가이드
   - config.py의 페이지 마커 설정 필수 공유
   - 보호 블록 및 제거 요소 설정 방법 문서화
   - 협업자들의 일관된 전처리 보장
```

---

## [5] 오늘 분석/실험 중 얻은 인사이트나 발견한 문제점은?
**답변**:
```
주요 인사이트:

1. chunk_hash 기반 중복 관리의 효과
   - 동일 파일 재처리 시 변경된 청크만 업데이트
   - FAISS 인덱스 크기 증가 방지
   - API 호출 비용 절감 (중복 임베딩 생성 방지)

2. 거리 기반 점수의 우수성
   - 정규화 없이 원본 메트릭 보존
   - 벡터 공간에서의 실제 거리 반영
   - 검색 품질 평가에 더 유용

3. 페이지 단위 청킹의 장점
   - 문서 구조 보존 (페이지 경계)
   - 출처 추적 용이 (start_page, end_page)
   - chunk_type으로 청킹 전략 추적 가능

발견한 문제점:

1. 더미 데이터 관리 이슈
   - 빈 인덱스 초기화 시 더미 문서 자동 생성
   - 첫 실제 데이터 추가 시 더미 자동 삭제로 해결

2. chunk_map 재구축 비용
   - 인덱스 재구성 시 chunk_map 전체 재구축 필요
   - 삭제 작업이 빈번할 경우 성능 저하 가능성
   - 향후 최적화 필요
```

---

## [6] 일정 지연이나 협업 중 어려웠던 점이 있다면?
**답변**:
```
1. chunk_hash 중복 관리 로직 복잡도
   - (file_hash, chunk_index) 키 기반 매핑 구조 설계
   - 삭제/추가 시 chunk_map 일관성 유지 로직 필요
   - 재구축 시점 판단 및 최적화 고민

2. 마크다운 전처리 테스트 케이스 작성
   - 다양한 엣지 케이스 발견 (중첩 코드블록, 탈출문자 등)
   - 보호 블록과 제거 요소 간 우선순위 결정 필요
   - 25개 테스트 케이스 작성 및 검증에 시간 소요

3. 설계 문서와 실제 코드 동기화
   - 구현 변경 시 설계 문서 즉시 업데이트 필요
   - 다이어그램 수정 작업 반복
   - 문서화 작업량 예상보다 많음
```

---

## [7] 오늘 발표 준비나 커뮤니케이션에서 기여한 부분은?
**답변**:
```
1. 시스템 아키텍처 설계서 v3.0 작성
   - 전체 시스템 구조 및 데이터 흐름 명확화
   - 모든 다이어그램 실제 코드 반영
   - 팀원들의 이해도 향상을 위한 상세 설명 추가

2. config.py 설정 가이드 공유
   - 페이지 마커 설정 필수 항목 공유
   - 마크다운 전처리 옵션 설명
   - 협업자들의 일관된 데이터 처리 보장

3. 기술적 의사결정 문서화
   - 거리 기반 점수 사용 이유 설명
   - chunk_hash 중복 관리 전략 공유
   - 향후 유지보수를 위한 기술 노트 작성
```

---

## [8] 내일 목표 / 할 일
**답변**:
```
1. 전체 시스템 통합 테스트
   - DocumentProcessor → EmbeddingProcessor → VectorStoreManager 파이프라인 검증
   - 실제 PDF 파일로 end-to-end 테스트
   - 검색 품질 평가 (거리 값 기반)

2. Retrieval 모듈 구현
   - VectorStoreManager와 연동
   - 검색 결과 포맷팅
   - LLMProcessor와 인터페이스 정의

3. 성능 최적화
   - chunk_map 재구축 최적화
   - FAISS 인덱스 크기 모니터링
   - 메모리 사용량 측정

4. 문서화 완성
   - API 문서 작성
   - 사용 예제 코드 작성
   - 트러블슈팅 가이드 추가
```

---

## [9] 추가 기록 (선택사항)

```
=== 핵심 기술 구현 세부사항 ===

1. VectorStoreManager 중복 관리 시스템
   - chunk_map: Dict[Tuple[str, int], Tuple[int, str]]
   - 키: (file_hash, chunk_index)
   - 값: (faiss_idx, chunk_hash)
   - 중복 체크: O(1) 시간복잡도
   - 스마트 업데이트: chunk_hash 비교로 변경된 청크만 교체

2. 마크다운 전처리 함수 (clean_markdown_text)
   - 보호 블록: 코드, 수식, 페이지마커
   - 제거 요소: HTML, 이미지, 링크, 강조, 헤더
   - 순차 교체 방식으로 중복 방지
   - 25개 테스트 케이스 100% 통과

3. 페이지 단위 청킹 전략
   - 페이지별로 텍스트 버퍼에 누적
   - chunk_size 초과 시 RecursiveCharacterTextSplitter로 분할
   - chunk_type 자동 분류: single, merged, split
   - start_page, end_page 메타데이터 자동 할당

4. 거리 기반 점수 체계
   - FAISS L2 거리 값 직접 사용
   - 정규화 없음 (원본 메트릭 보존)
   - 거리 해석 가이드: 0~0.5(매우 높음), 0.5~1.0(높음), 1.0~2.0(중간)

=== 개발 통계 ===
- 수정 파일: 4개 (VectorStoreManager, EmbeddingProcessor, DocumentsDB, 설계서)
- 추가 메서드: 8개
- 테스트 케이스: 25개 (100% 통과)
- 문서화: 시스템 아키텍처 설계서 v3.0 (1,226 라인)

=== 기술 스택 ===
- FAISS: 벡터 인덱싱 및 L2 거리 기반 유사도 검색
- LangChain: Document.metadata 기반 메타데이터 통합 관리
- SQLite: 문서 텍스트 및 채팅 히스토리 저장
- OpenAI: text-embedding-3-small 모델
```

---

**작성 시간**: 20분