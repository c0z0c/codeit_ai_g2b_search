# -*- coding: utf-8 -*-
"""
RAG ê¸°ë°˜ PEP ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ
Streamlit UI
"""

import streamlit as st
import os
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from src.db import DocumentsDB, ChatHistoryDB
from src.llm.retrieval import Retrieval
from src.llm.llm_processor import LLMProcessor
from src.config import get_config

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG ê¸°ë°˜ PEP ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Config ì´ˆê¸°í™”
@st.cache_resource
def init_config():
    """Config ì‹±ê¸€í†¤ ë¡œë“œ"""
    return get_config()

config = init_config()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'session_id' not in st.session_state:
    st.session_state.session_id = None
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'api_key' not in st.session_state:
    st.session_state.api_key = config.OPENAI_API_KEY or os.getenv('OPENAI_API_KEY', '')

# DB ì´ˆê¸°í™”
@st.cache_resource
def init_dbs():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    cfg = get_config()
    return {
        'docs': DocumentsDB(cfg.DOCUMENTS_DB_PATH),
        'chat': ChatHistoryDB(cfg.CHAT_HISTORY_DB_PATH)
    }

dbs = init_dbs()

# === ì‚¬ì´ë“œë°” ===
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")

    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API Key",
        value=st.session_state.api_key,
        type="password",
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    if api_key:
        st.session_state.api_key = api_key
        os.environ['OPENAI_API_KEY'] = api_key

    st.divider()

    # ë°ì´í„° í†µê³„
    # !!!DocumentsDB í´ë˜ìŠ¤ê°€ ì—†ê¸° ë•Œë¬¸ì— ImportError ë˜ëŠ” AttributeError ê°€ ë‚©ë‹ˆë‹¤. (11/11 ì¶”ê°€) ***ê¹Œì§€!!!
    st.subheader("ğŸ“Š ë°ì´í„° í†µê³„")
    #doc_stats = dbs['docs'].get_document_stats()
    #embedding_stats = dbs['embeddings'].get_embedding_stats()

    #í•´ê²° ë°©ë²• (UIë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì„ ë•Œ) ë§Œì•½ UIë§Œ ë³´ê³  ì‹¶ë‹¤ë©´, dbs['docs'] ê´€ë ¨ ë¶€ë¶„ì„ ë”ë¯¸ë¡œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤.
    # ë”ë¯¸ ë°ì´í„°ë¡œ êµì²´
    doc_stats = {'total_files': 0, 'total_pages': 0}
    embedding_stats = {'total_embeddings': 0, 'total_chunks': 0}
    #                   *** ì—¬ê¸°ê¹Œì§€ UI í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ì¶”ê°€ (ì¶”í›„ì‚­ì œ) ***

    col1, col2 = st.columns(2)
    with col1:
        st.metric("ë¬¸ì„œ ìˆ˜", f"{doc_stats['total_files']}")
        st.metric("í˜ì´ì§€ ìˆ˜", f"{doc_stats['total_pages']}")
    with col2:
        st.metric("ì„ë² ë”© ìˆ˜", f"{embedding_stats['total_embeddings']}")
        st.metric("ì²­í¬ ìˆ˜", f"{embedding_stats['total_chunks']}")

    st.divider()

    # ì„¸ì…˜ ê´€ë¦¬
    st.subheader("ğŸ’¬ ì±„íŒ… ì„¸ì…˜")

    # ìƒˆ ì„¸ì…˜ ìƒì„±
    if st.button("â• ìƒˆ ì±„íŒ… ì‹œì‘", use_container_width=True):
        session_name = f"ì±„íŒ… {len(dbs['chat'].get_all_sessions()) + 1}"
        new_session_id = dbs['chat'].create_session(session_name)
        st.session_state.session_id = new_session_id
        st.session_state.messages = []
        st.rerun()

    # ê¸°ì¡´ ì„¸ì…˜ ëª©ë¡
    sessions = dbs['chat'].get_recent_sessions(limit=10)
    if sessions:
        st.write("ìµœê·¼ ì„¸ì…˜:")
        for session in sessions:
            is_current = session['session_id'] == st.session_state.session_id
            label = f"{'ğŸŸ¢' if is_current else 'âšª'} {session['session_name']}"
            if st.button(label, key=session['session_id'], use_container_width=True):
                st.session_state.session_id = session['session_id']
                # ì„¸ì…˜ ë©”ì‹œì§€ ë¡œë“œ
                messages = dbs['chat'].get_session_messages(session['session_id'])
                st.session_state.messages = [
                    {"role": msg['role'], "content": msg['content']}
                    for msg in messages
                ]
                st.rerun()

# === ë©”ì¸ ì˜ì—­ ===
st.title("ğŸ“š RAG ê¸°ë°˜ PEP ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
st.markdown("ê³µê³µë°ì´í„° ë° AI ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì§ˆë¬¸í•˜ì„¸ìš”.")

# ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±
if st.session_state.session_id is None:
    st.session_state.session_id = dbs['chat'].create_session()

# ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # API í‚¤ í™•ì¸
    if not st.session_state.api_key:
        st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        st.stop()

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # DBì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    dbs['chat'].add_message(st.session_state.session_id, "user", prompt)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            # ì„ë² ë”© ê°€ì ¸ì˜¤ê¸° (ì²« ë²ˆì§¸ ì„ë² ë”© ì‚¬ìš©)
            all_embeddings = dbs['embeddings'].get_all_embeddings()

            if not all_embeddings:
                response = "ì„ë² ë”©ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì„ë² ë”©ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
            else:
                embedding_hash = all_embeddings[0]['embedding_hash']

                # ê²€ìƒ‰ ìˆ˜í–‰ (Configì˜ TOP_K_FINAL ì‚¬ìš©)
                retrieval = Retrieval(config=config)
                retrieved_chunks = retrieval.search(
                    query=prompt,
                    embedding_hash=embedding_hash,
                    top_k=config.TOP_K_FINAL,
                    api_key=st.session_state.api_key
                )

                # LLM ì‘ë‹µ ìƒì„±
                llm = LLMProcessor(config=config)
                response = llm.generate_response(
                    query=prompt,
                    retrieved_chunks=retrieved_chunks,
                    api_key=st.session_state.api_key
                )

                # ì¶œì²˜ í‘œì‹œ
                if retrieved_chunks:
                    response += "\n\n---\n**ğŸ“„ ì°¸ê³  ë¬¸ì„œ:**\n"
                    for i, chunk in enumerate(retrieved_chunks, 1):
                        file_name = chunk.get('file_name', 'unknown')
                        similarity = chunk.get('similarity', 0)
                        response += f"\n{i}. {file_name} (ìœ ì‚¬ë„: {similarity:.2%})"

        st.markdown(response)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": response})

    # DBì— ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
    retrieved_info = [
        {
            "file_name": chunk.get('file_name'),
            "similarity": float(chunk.get('similarity', 0))
        }
        for chunk in retrieved_chunks
    ] if 'retrieved_chunks' in locals() and retrieved_chunks else None

    dbs['chat'].add_message(
        st.session_state.session_id,
        "assistant",
        response,
        retrieved_chunks=retrieved_info
    )

# í‘¸í„°
st.divider()
st.caption("ğŸ’¡ Tip: ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ê³ , ìƒˆ ì±„íŒ…ì„ ì‹œì‘í•˜ê±°ë‚˜ ê¸°ì¡´ ì±„íŒ…ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
